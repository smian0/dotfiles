{
  "$schema": "https://opencode.ai/config.json",
  "theme": "opencode",
  "model": "ollamat/gpt-oss:120b",
  "autoupdate": true,
  "provider": {
    "ollama": {
      "npm": "@ai-sdk/openai-compatible",
      "name": "Ollama (local)",
      "options": {
        "baseURL": "http://localhost:3304/v1"
      },
      "models": {
        "gpt-oss:20b": {
          "name": "GPT-OSS 20B (Local)"
        },
        "gpt-oss:120b": {
          "name": "GPT-OSS 120B (Local)"
        },
        "deepseek-v3.1:671b": {
          "name": "DeepSeek V3.1 671B (Local)"
        }
      }
    },
    "ollamat": {
      "npm": "ollama-ai-provider-v2",
      "name": "Ollama (turbo)",
      "options": {
        "baseURL": "https://ollama.com/api",
        "headers": {
          "Authorization": "Bearer {env:OLLAMA_API_KEY}"
        }
      },
      "models": {
        "gpt-oss:20b": {
          "name": "GPT-OSS 20B (Turbo)"
        },
        "gpt-oss:120b": {
          "name": "GPT-OSS 120B (Turbo)"
        },
        "deepseek-v3.1:671b": {
          "name": "DeepSeek V3.1 671B (Turbo)"
        }
      }
    }
  },
  "mcp": {
    "markdown": {
      "type": "local",
      "command": ["uv", "run", "/Users/smian/dotfiles/claude/.claude/mcp_servers/mcp_markdown/server.py"],
      "enabled": true
    },
    "streamable-mcp-server": {
      "type": "remote",
      "url": "http://127.0.0.1:12306/mcp",
      "enabled": false
    }
  },
  "tools": {
    "mcp__markdown__*": true
  },
  "agent": {
    "plan": {
      "model": "ollamat/gpt-oss:120b"
    },
    "build": {
      "model": "ollamat/gpt-oss:120b"
    },
    "general": {
      "model": "ollamat/gpt-oss:120b"
    },
     "reasoning": {
       "model": "ollamat/gpt-oss:120b",
       "system": "You are a highâ€‘quality reasoning assistant. Always provide step-by-step <reasoning></reasoning> tags before the final answer.",
       "reasoningEffort": "medium"
     },
     "websearch": {
       "model": "ollamat/gpt-oss:120b",
       "system": "You are a concise web-search assistant. Retrieve the most relevant information for the given query and return a short factual summary (max 3 sentences). Cite the source URL at the end.",
       "reasoningEffort": "medium"
     },
     "markdown-pro": {
       "model": "ollamat/gpt-oss:120b",
       "temperature": 0.1,
       "system": "{file:./prompts/markdown-specialist.md}",
       "tools": {
         "mcp__markdown__*": true
       }
     },
     "news": {
       "model": "ollamat/gpt-oss:120b",
       "system": "{file:./agent/news.md}"
     }
  }
}